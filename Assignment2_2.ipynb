{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# FDU PRML 2023 Fall Assignment 2.1\n",
    "\n",
    "Name: 干磊  \n",
    "<your name>\n",
    "Student ID: 21307130211\n",
    "<your student id>\n",
    "\n",
    "<font color='red'>**Deadline: 2023-11-20 23:59**</font>\n",
    "<font color='red'>**Overall score weight: 70/100**</font>\n",
    "\n",
    "In this semester, we are going to complete 3 assignments, each may contain **2-3 parts**. This is the second (and the last) part of the second assignment, in which we will get to implement our own Pytorch-like library.\n",
    "\n",
    "## 1. FDUNN: your toy torch-like deep learning library (40 points)\n",
    "\n",
    "In this assignment, you will fist implement your own torch-like deep learning library with `numpy`, named `fdunn`.\n",
    "\n",
    "PyTorch: [Link](https://pytorch.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# setup code, auto reload your .py file\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "np.random.seed(233)\n",
    "\n",
    "# matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You have to impletement several standard deep neural network modules in the `./fdunn` folder:\n",
    "1.   linear/conv/pooling\n",
    "2.   activation\n",
    "3.   loss\n",
    "4.   optim\n",
    "5.   trainer\n",
    "\n",
    "We have written most of the code for you already, and you only need to fill in the most essential parts. We have also prepared several test cases for you to check if your code works correctly.\n",
    "\n",
    "Furthermore, you can also test the accuracy of your code by comparing its output with the output of sk-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "#### 注：下面会对自己实现的几个模块进行测试\n",
    "测试方式是：取torch里面对应的模块，然后给同样的输入，检查输出是否相同\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 test Linear\n",
    "\n",
    "We'll compare it with torch.nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\AelearningFile\\InClass\\2023Autumn\\PRML\\Assignment\\AS2\\2_2\n",
      "['d:\\\\AelearningFile\\\\InClass\\\\2023Autumn\\\\PRML\\\\Assignment\\\\AS2\\\\2_2', 'd:\\\\software\\\\Conda\\\\envs\\\\conflict\\\\python310.zip', 'd:\\\\software\\\\Conda\\\\envs\\\\conflict\\\\DLLs', 'd:\\\\software\\\\Conda\\\\envs\\\\conflict\\\\lib', 'd:\\\\software\\\\Conda\\\\envs\\\\conflict', '', 'd:\\\\software\\\\Conda\\\\envs\\\\conflict\\\\lib\\\\site-packages', 'd:\\\\software\\\\Conda\\\\envs\\\\conflict\\\\lib\\\\site-packages\\\\win32', 'd:\\\\software\\\\Conda\\\\envs\\\\conflict\\\\lib\\\\site-packages\\\\win32\\\\lib', 'd:\\\\software\\\\Conda\\\\envs\\\\conflict\\\\lib\\\\site-packages\\\\Pythonwin', 'd:\\\\AelearningFile\\\\InClass\\\\2023Autumn\\\\PRML\\\\Assignment\\\\AS2\\\\2_2', 'd:\\\\AelearningFile\\\\InClass\\\\2023Autumn\\\\PRML\\\\Assignment\\\\AS2\\\\2_2', 'd:\\\\AelearningFile\\\\InClass\\\\2023Autumn\\\\PRML\\\\Assignment\\\\AS2\\\\2_2', 'd:\\\\AelearningFile\\\\InClass\\\\2023Autumn\\\\PRML\\\\Assignment\\\\AS2\\\\2_2']\n",
      "Output equal\n",
      "grad_x equal\n",
      "grad_w equal\n",
      "grad_b equal\n"
     ]
    }
   ],
   "source": [
    "#from fdunn import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fdunn.modules.linear import Linear\n",
    "\n",
    "# test Linear\n",
    "input_dim = 16\n",
    "output_dim = 32\n",
    "X = torch.randn(4,input_dim,requires_grad=True)\n",
    "torch_linear = nn.Linear(input_dim,output_dim)\n",
    "fdu_linear   = Linear(input_dim,output_dim)\n",
    "\n",
    "torch_linear.weight.data = torch.Tensor(fdu_linear.params['W'])\n",
    "torch_linear.bias.data = torch.Tensor(fdu_linear.params['b'])\n",
    "\n",
    "torch_linear.train()\n",
    "y_torch = torch_linear(X)\n",
    "y_fdu   = fdu_linear(X.detach().numpy())\n",
    "\n",
    "#check output\n",
    "np.testing.assert_allclose(y_fdu, y_torch.detach().numpy(), rtol=1e-5, atol=1e-5)\n",
    "print('Output equal')\n",
    "\n",
    "\n",
    "grad_y_torch = torch.ones_like(y_torch)\n",
    "y_torch.backward(grad_y_torch)\n",
    "grad_x_fdu = fdu_linear.backward(grad_y_torch.numpy())\n",
    "grad_w_torch = torch_linear.weight.grad.numpy()\n",
    "grad_b_torch = torch_linear.bias.grad.numpy()\n",
    "\n",
    "# check grad\n",
    "np.testing.assert_allclose(grad_x_fdu, X.grad.detach().numpy(), rtol=1e-5, atol=1e-5)\n",
    "print('grad_x equal')\n",
    "np.testing.assert_allclose(fdu_linear.grads['W'], grad_w_torch, rtol=1e-5, atol=1e-5)\n",
    "print('grad_w equal')\n",
    "np.testing.assert_allclose(fdu_linear.grads['b'], grad_b_torch, rtol=1e-5, atol=1e-5)\n",
    "print('grad_b equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Conv2d Test\n",
    "compare ours with torch.nn.Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output equal\n",
      "grad_x equal\n",
      "grad_w equal\n",
      "grad_b equal\n"
     ]
    }
   ],
   "source": [
    "from fdunn.modules.conv import Conv2d\n",
    "\n",
    "in_channels = 2\n",
    "out_channels = 3\n",
    "kernel_size  = 3\n",
    "\n",
    "conv_torch = nn.Conv2d(in_channels,out_channels,kernel_size)\n",
    "conv_fdu = Conv2d(in_channels,out_channels,kernel_size)\n",
    "\n",
    "conv_torch.weight.data = torch.Tensor(conv_fdu.params['W'])\n",
    "conv_torch.bias.data = torch.Tensor(conv_fdu.params['b'])\n",
    "\n",
    "\n",
    "X = torch.randn(4,in_channels,28,28,requires_grad=True)\n",
    "y_torch = conv_torch(X)\n",
    "y_fdu = conv_fdu(X.detach().numpy())\n",
    "\n",
    "#check output\n",
    "np.testing.assert_allclose(y_fdu, y_torch.detach().numpy(), rtol=1e-5, atol=1e-5)\n",
    "print('Output equal')\n",
    "\n",
    "#check gradient\n",
    "grad_y_torch = torch.ones_like(y_torch)\n",
    "y_torch.backward(grad_y_torch)\n",
    "grad_x_fdu = conv_fdu.backward(grad_y_torch.numpy())\n",
    "grad_w_torch = conv_torch.weight.grad.numpy()\n",
    "grad_b_torch = conv_torch.bias.grad.numpy()\n",
    "\n",
    "np.testing.assert_allclose(grad_x_fdu, X.grad.detach().numpy(), rtol=1e-5, atol=1e-4)\n",
    "print('grad_x equal')\n",
    "np.testing.assert_allclose(conv_fdu.grads['W'], grad_w_torch, rtol=1e-5, atol=1e-4)\n",
    "print('grad_w equal')\n",
    "\n",
    "np.testing.assert_allclose(conv_fdu.grads['b'], grad_b_torch, rtol=1e-5, atol=1e-4)\n",
    "print('grad_b equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 MaxPool2d Test\n",
    "\n",
    "We'll compare it with torch.nn.MaxPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output equal\n",
      "grad_x equal\n"
     ]
    }
   ],
   "source": [
    "from fdunn.modules.pooling import MaxPool2d\n",
    "\n",
    "kernel_size = 2\n",
    "stride = 2\n",
    "pool_fdu = MaxPool2d(kernel_size=kernel_size,stride=stride)\n",
    "pool_torch = torch.nn.MaxPool2d(kernel_size=kernel_size,stride=stride)\n",
    "\n",
    "X = torch.randn(4,3,28,28,requires_grad=True)\n",
    "y_torch = pool_torch(X)\n",
    "y_fdu = pool_fdu(X.detach().numpy())\n",
    "\n",
    "#check output\n",
    "np.testing.assert_allclose(y_fdu, y_torch.detach().numpy(), rtol=1e-5, atol=1e-5)\n",
    "print('Output equal')\n",
    "\n",
    "#check gradient\n",
    "grad_y_torch = torch.ones_like(y_torch)\n",
    "y_torch.backward(grad_y_torch)\n",
    "grad_x_fdu = pool_fdu.backward(grad_y_torch.numpy())\n",
    "\n",
    "np.testing.assert_allclose(grad_x_fdu, X.grad.detach().numpy(), rtol=1e-5, atol=1e-4)\n",
    "print('grad_x equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Sigmoid Test\n",
    "\n",
    "compare it with torch.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output equal\n",
      "grad_x equal\n"
     ]
    }
   ],
   "source": [
    "from fdunn.modules.activation import Sigmoid\n",
    "\n",
    "sigmoid_fdu = Sigmoid()\n",
    "X = torch.randn(4,3,28,28,requires_grad=True)\n",
    "y_torch = torch.sigmoid(X)\n",
    "y_fdu = sigmoid_fdu(X.detach().numpy())\n",
    "#check output\n",
    "np.testing.assert_allclose(y_fdu, y_torch.detach().numpy(), rtol=1e-5, atol=1e-5)\n",
    "print('Output equal')\n",
    "\n",
    "#check gradient\n",
    "grad_y_torch = torch.ones_like(y_torch)\n",
    "y_torch.backward(grad_y_torch)\n",
    "grad_x_fdu = sigmoid_fdu.backward(grad_y_torch.numpy())\n",
    "\n",
    "np.testing.assert_allclose(grad_x_fdu, X.grad.detach().numpy(), rtol=1e-5, atol=1e-4)\n",
    "print('grad_x equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Test CrossEntropy\n",
    "\n",
    "We'll compare it with torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output equal\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "from fdunn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "class IdentityModel():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input):\n",
    "        return input\n",
    "\n",
    "    def backward(self, output_grad):\n",
    "        return output_grad\n",
    "\n",
    "y_pred = torch.randn(4,10)\n",
    "y_true = torch.randn(4,10)\n",
    "loss_torch = cross_entropy(y_pred,y_true)\n",
    "CE_fdu     = CrossEntropyLoss(IdentityModel)\n",
    "loss_fdu   = CE_fdu(y_pred.numpy(),y_true.numpy())\n",
    "\n",
    "np.testing.assert_allclose(loss_fdu,loss_torch.detach().numpy(), rtol=1e-5, atol=1e-5)\n",
    "print('Output equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Deep Learning with Image/Text Data (20 points)\n",
    "\n",
    "Use your fdunn lib to perform image classification on MNIST or CIFAR10 dataset.\n",
    "\n",
    "- MNIST: http://yann.lecun.com/exdb/mnist/\n",
    "- CIFAR10: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#get dataset using torch\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 定义数据转换，将图像转换为张量并归一化\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "batch = 16\n",
    "\n",
    "# 获取MNIST训练数据集\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=False)\n",
    "train_loader  = DataLoader(train_dataset,batch_size=batch,shuffle=True)\n",
    "# 获取MNIST测试数据集\n",
    "test_dataset  = datasets.MNIST(root='./data', train=False, transform=transform, download=False)\n",
    "test_loader   = DataLoader(test_dataset ,batch_size=batch,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fdunn.modules.base import Module\n",
    "from fdunn.modules.activation import ReLU\n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self) -> None:\n",
    "        self.conv1 = Conv2d(1,6,5)\n",
    "        self.relu1 = ReLU()\n",
    "        self.pool1  = MaxPool2d(2,2)\n",
    "        self.conv2 = Conv2d(6,16,3)\n",
    "        self.relu2 = ReLU()\n",
    "        self.pool2  = MaxPool2d(2,2)\n",
    "        self.fc1   = Linear(16*5*5,120)\n",
    "        self.relu3 = ReLU()\n",
    "        self.fc2   = Linear(120,84)\n",
    "        self.relu4 = ReLU()\n",
    "        self.fc3   = Linear(84,10)\n",
    "        self.layers = {\n",
    "            'conv1':self.conv1,\n",
    "            'relu1':self.relu1,\n",
    "            'pool1':self.pool1,\n",
    "            'conv2':self.conv2,\n",
    "            'relu2':self.relu2,\n",
    "            'pool2':self.pool2,\n",
    "            'fc1':self.fc1,\n",
    "            'relu3':self.relu3,\n",
    "            'fc2':self.fc2,\n",
    "            'relu4':self.relu4,\n",
    "            'fc3':self.fc3}\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        grad = self.fc3.backward(output_grad)\n",
    "        grad = self.relu4.backward(grad)\n",
    "        grad = self.fc2.backward(grad)\n",
    "        grad = self.relu3.backward(grad)\n",
    "        grad = self.fc1.backward(grad)\n",
    "        \n",
    "        grad = grad.reshape(-1, 16, 5, 5)  # 恢复pooling之前的形状\n",
    "        \n",
    "        grad = self.pool2.backward(grad)\n",
    "        grad = self.relu2.backward(grad)\n",
    "        grad = self.conv2.backward(grad)\n",
    "        \n",
    "        grad = self.pool1.backward(grad)\n",
    "        grad = self.relu1.backward(grad)\n",
    "        grad = self.conv1.backward(grad)\n",
    "        \n",
    "        return grad\n",
    "\n",
    "model = Model()\n",
    "\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss history:\n",
      " [8638.4501953125, 8581.294921875, 7591.48486328125, 2252.728515625, 1053.446044921875, 752.1578369140625, 605.9782104492188, 517.53955078125, 459.9164123535156, 417.7870788574219, 386.4608459472656, 359.871826171875, 338.58831787109375, 320.2797546386719, 304.1206970214844, 289.1596984863281, 276.3130187988281, 263.42071533203125, 254.5855255126953, 245.12893676757812, 236.19668579101562, 227.7873077392578, 220.13450622558594, 210.99118041992188, 206.568115234375, 200.12147521972656, 194.1234588623047, 188.2694549560547, 183.5987548828125, 177.21812438964844, 173.2720489501953, 168.22998046875, 164.48477172851562, 160.5376739501953, 157.07977294921875, 151.9627227783203, 148.963623046875, 145.983642578125, 141.44326782226562, 138.97506713867188, 136.67054748535156, 132.89529418945312, 130.31771850585938, 127.20108032226562, 124.59286499023438, 120.96067810058594, 119.96495819091797, 117.07197570800781, 113.61637115478516, 111.7655029296875, 110.50514221191406]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from fdunn.optim.sgd import SGD\n",
    "from fdunn.optim.adam import Adam\n",
    "\n",
    "from fdunn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "optimizer = SGD(model,lr=0.01)\n",
    "#optimizer = Adam(model,lr=0.01)\n",
    "loss_fn = CrossEntropyLoss(model)\n",
    "\n",
    "num_epoch = 0 #50\n",
    "\n",
    "def one_hot(labels,num_classes):\n",
    "    one_hot_labels = np.zeros((labels.shape[0], num_classes), dtype=np.float32)\n",
    "    one_hot_labels[np.arange(labels.shape[0]), labels] = 1\n",
    "\n",
    "    return one_hot_labels\n",
    "\n",
    "\n",
    "\n",
    "mode    = 'train'\n",
    "\n",
    "if len(loss_history)>0:\n",
    "    # if already trained , print loss_history\n",
    "    print('loss history:\\n',loss_history)\n",
    "else:\n",
    "    # train from scratch\n",
    "    for epoch in range(num_epoch):\n",
    "        loss_total = 0\n",
    "        for i_batch,datum in tqdm(enumerate(train_loader),desc=f'epoch{epoch}',total=len(train_loader)):\n",
    "            X = datum[0].numpy()\n",
    "            label = datum[1].numpy()\n",
    "            y = one_hot(label,10)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred,y)\n",
    "            label_pred = np.argmax(y_pred, 1)\n",
    "            #print(label_pred == label)\n",
    "            correct = (label_pred == label).sum()\n",
    "            #acc_cnt += correct.item()\n",
    "            loss_total+=loss.item()\n",
    "            #num_exp += batch        \n",
    "            if mode =='train':\n",
    "                loss_fn.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "        loss_history.append(loss_total)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [12:17<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 0     is 99.8 %\n",
      "Accuracy for 1     is 99.0 %\n",
      "Accuracy for 2     is 98.5 %\n",
      "Accuracy for 3     is 99.3 %\n",
      "Accuracy for 4     is 98.9 %\n",
      "Accuracy for 5     is 98.9 %\n",
      "Accuracy for 6     is 97.4 %\n",
      "Accuracy for 7     is 99.3 %\n",
      "Accuracy for 8     is 95.9 %\n",
      "Accuracy for 9     is 98.0 %\n",
      "Average Acc: 98.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9' )\n",
    "# Measure accuracy for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "for data in tqdm(test_loader):\n",
    "    images, labels = data\n",
    "    outputs = model(images.numpy())\n",
    "    predictions = np.argmax(outputs, 1)\n",
    "    # collect the correct predictions for each class\n",
    "    for label, prediction in zip(labels, predictions):\n",
    "        if label == prediction:\n",
    "            correct_pred[classes[label]] += 1\n",
    "        total_pred[classes[label]] += 1\n",
    "\n",
    "# Print accuracy statistics\n",
    "average_accuray = []\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    average_accuray.append(accuracy)\n",
    "    print(f'Accuracy for {classname:5s} is {accuracy:.1f} %')\n",
    "print (f'Average Acc: {np.mean(average_accuray):.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Advanced Topics (10 points)\n",
    "\n",
    "You can try to implement some advanced topics in deep learning with our fdunn in this section.\n",
    "\n",
    "We will divide the topics into two categories: modules and optimization, with 5 points for each category.\n",
    "\n",
    "### 3.1 Modules\n",
    "\n",
    "Pick one of the following (trending or classic) topics and implement it with fdunn. Try to implement it and design a toy test case to show that your implementation is correct (say we can compare the forward and backward results with the results of corresponding Pytorch modules with the same weight).\n",
    "\n",
    "- Batch/Layer/Group Normalization (just one of them is fine)\n",
    "- A ReLU/GeLU/SiLU activation function (just one of them is fine)\n",
    "- A Gated Linear Unit (GLU)\n",
    "- An RNN cell\n",
    "- Or any other modules you are interested in\n",
    "\n",
    "\n",
    "### 3.2 Optimization\n",
    "\n",
    "Pick one of the following optimization methods and implement it with fdunn.\n",
    "\n",
    "- SGD with L2 regularization. (Try to repeat your experiment in Assignment 1.1 to see the same 'underregularization' to 'overregularization' phenomenon)\n",
    "- Adam (Does it converge faster than SGD in the last section?)\n",
    "- Or any other optimization methods you are interested in (I am far from an expert in optimization, so maybe you can teach me something new here. Say a second order method?)\n",
    "\n",
    "\n",
    "If you are not sure about what to do, We suggest you to implement the ReLU activation function and SGD with L2 regularization. They are foundamental and (relatively) easy to implement.\n",
    "\n",
    "Different methods do not vary in scores. So do not chase fancy methods unless you are quite interested in them.\n",
    "\n",
    "There are many ways to prove your implementation is correct, as long as they are convincing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1 Relu\n",
    "\n",
    "I choose to implement ReLU as it is really useful \n",
    "\n",
    "The definition of class ReLU is in `modules/activation.py`\n",
    "\n",
    "And I have already used ReLU in the model for MNIST classification task\n",
    "\n",
    "The following code tests if my ReLU is the same as torch.nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output equal\n",
      "grad_x equal\n"
     ]
    }
   ],
   "source": [
    "from fdunn.modules.activation import ReLU\n",
    "\n",
    "\n",
    "ReLU_fdu = ReLU()\n",
    "ReLU_torch = torch.nn.ReLU()\n",
    "\n",
    "X = torch.randn(4,32,32,requires_grad=True)\n",
    "y_torch = ReLU_torch(X)\n",
    "y_fdu   = ReLU_fdu(X.detach().numpy())\n",
    "\n",
    "#check output\n",
    "np.testing.assert_allclose(y_fdu, y_torch.detach().numpy(), rtol=1e-5, atol=1e-5)\n",
    "print('Output equal')\n",
    "\n",
    "#check gradient\n",
    "grad_y_torch = torch.ones_like(y_torch)\n",
    "y_torch.backward(grad_y_torch)\n",
    "grad_x_fdu = ReLU_fdu.backward(grad_y_torch.numpy())\n",
    "\n",
    "np.testing.assert_allclose(grad_x_fdu, X.grad.detach().numpy(), rtol=1e-5, atol=1e-4)\n",
    "print('grad_x equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Adam\n",
    "\n",
    "Implement our Adam in `fdunn\\modules\\optim\\adam.py`\n",
    "\n",
    "在上一个section已经有用过Adam进行训练  \n",
    "下面画出用两种优化器训练时，不同epoch对应的loss曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2a412f5ebf0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#下面画出用两种方式进行训练，不同epoch时的loss曲线\n",
    "Adam_loss = [8638.4501953125,620.7177124023438, 213.89102172851562, 151.4208526611328, 121.59040069580078, 102.30972290039062, 84.56820678710938, 70.83726501464844, 63.41128158569336, 59.32310104370117, 49.94365310668945, 47.72056579589844, 44.224159240722656, 44.746707916259766, 37.37348937988281, 44.117801666259766, 40.23704528808594, 36.00308609008789, 35.042484283447266, 30.296903610229492, 33.94499969482422]\n",
    "SGD_loss = [8638.4501953125,8581.294921875, 7591.48486328125, 2252.728515625, 1053.446044921875, 752.1578369140625, 605.9782104492188, 517.53955078125, 459.9164123535156, 417.7870788574219, 386.4608459472656, 359.871826171875, 338.58831787109375, 320.2797546386719, 304.1206970214844, 289.1596984863281, 276.3130187988281, 263.42071533203125, 254.5855255126953, 245.12893676757812, 236.19668579101562, 227.7873077392578, 220.13450622558594, 210.99118041992188, 206.568115234375, 200.12147521972656, 194.1234588623047, 188.2694549560547, 183.5987548828125, 177.21812438964844, 173.2720489501953, 168.22998046875, 164.48477172851562, 160.5376739501953, 157.07977294921875, 151.9627227783203, 148.963623046875, 145.983642578125, 141.44326782226562, 138.97506713867188, 136.67054748535156, 132.89529418945312, 130.31771850585938, 127.20108032226562, 124.59286499023438, 120.96067810058594, 119.96495819091797, 117.07197570800781, 113.61637115478516, 111.7655029296875, 110.50514221191406]\n",
    "\n",
    "plt.plot(list(range(len(Adam_loss))),Adam_loss,label='Adam')\n",
    "plt.plot(list(range(len(SGD_loss))),SGD_loss,label='SGD')\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlabel('Cross Entropy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch = 0 时表示初始的模型，没有进行训练  \n",
    "\n",
    "由图可见，Adam 相较与SGD可以快速地让loss下降  \n",
    "\n",
    "SGD的loss下降到150左右的时候，loss随epoch的下降变得极其缓慢，限于时间原因，这里没有再继续训练使其降低到100以下  \n",
    "\n",
    "Adam的loss可以快速下降，只需5轮训练即可降到100以下，20轮即接近收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### 3.3 补充：模型参数的保存和加载\n",
    "\n",
    "torch里面提供了方便的保存模型参数的方法，我们这里给出类似的保存参数的函数  \n",
    "要求是 model 的layers是一个字典，保存层的名字和该层模块\n",
    "\n",
    "提交的文件包含了model_ckpt.npy，所以助教老师可以验证下面代码的有效性和模型的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_dict(model):\n",
    "    state_dict = {}\n",
    "    for name, layer in model.layers.items():\n",
    "        if hasattr(layer, 'params'):\n",
    "            state_dict[name + '.weight'] = layer.params['W']\n",
    "            state_dict[name + '.bias'] = layer.params['b']\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def load_state_dict(state_dict_path, model):\n",
    "    state_dict = np.load(state_dict_path, allow_pickle=True).item()\n",
    "    for name, layer in model.layers.items():\n",
    "        if hasattr(layer, 'params'):\n",
    "            layer.params['W'] = state_dict[name + '.weight']\n",
    "            layer.params['b'] = state_dict[name + '.bias']\n",
    "            \n",
    "\n",
    "#保存checkpoint            \n",
    "saved_state_dict = get_state_dict(model)\n",
    "np.save('model_ckpt.npy', saved_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/625 [00:08<12:12,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Acc: 96.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#新建一个未训练的模型，并加载训练好的参数\n",
    "new_model = Model()\n",
    "load_state_dict('./model_ckpt.npy',new_model)\n",
    "\n",
    "\n",
    "#直接在100个样本上做推理\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9' )\n",
    "# Measure accuracy for each class\n",
    "\n",
    "cnt = 0\n",
    "correct_count = 0\n",
    "for data in tqdm(test_loader):\n",
    "    if (cnt>100):\n",
    "        break\n",
    "    cnt += batch\n",
    "    images, labels = data\n",
    "    labels = labels.numpy()\n",
    "    outputs = new_model(images.numpy())\n",
    "    predictions = np.argmax(outputs, 1)\n",
    "    correct_count += (labels == predictions).sum().item()\n",
    "    # collect the correct predictions for each class\n",
    "\n",
    "# Print accuracy statistics\n",
    "print (f'Average Acc: {(correct_count/cnt)*100:.1f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
